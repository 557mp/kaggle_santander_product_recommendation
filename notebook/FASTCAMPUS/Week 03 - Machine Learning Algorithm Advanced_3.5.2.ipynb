{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝 알고리즘 적용 _ 심화\n",
    "    - 데이터 : 사용자 데이터 + 상품 데이터(과거 상품 구매 이력)\n",
    "    - 신규 모델 : RandomForest, ExtraTrees, BaggingClassifier, (XGBoost)\n",
    "    - 업데이트된 데이터 + 기존 모델(DT, LR) 평가척도 \n",
    "    - 업데이트된 데이터 + 신규 모델 평가척도\n",
    "    - [+2] 피쳐 엔지니어링\n",
    "    - [+2] 매개변수 조정\n",
    "    - 캐글 제출 \n",
    "    - 머신러닝 파이프라인 흐름도 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 신규 데이터 로딩\n",
    "\n",
    "trn = pd.read_csv('../input/train_append_lb_lag.csv').fillna(0)\n",
    "target = pd.DataFrame(pickle.load(open('../input/target.pkl','rb')), columns=['target'])\n",
    "tst = pd.read_csv('../input/test_append_lb_lag.csv').fillna(0)\n",
    "print(trn.shape, target.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 신규 데이터 설명\n",
    "for col in trn.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터 동일 여부 확인\n",
    "trn.columns == tst.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 빈도가 낮은 타겟은 사전에 제거 (이유: 교차 검증에 활용할 수 없음 + 너무 빈도가 낮아 무의미함)\n",
    "rem_targets = [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23]  # 18 classes\n",
    "trn = trn[target['target'].isin(rem_targets)]\n",
    "target = target[target['target'].isin(rem_targets)]\n",
    "target = LabelEncoder().fit_transform(target)\n",
    "\n",
    "for t in np.unique(target):\n",
    "    print(t, sum(target==t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가용 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(x, y, model):\n",
    "    trn_scores = dict(); vld_scores = dict()\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.1, random_state=777)\n",
    "    for t_ind, v_ind in sss.split(x,y):\n",
    "        # split data\n",
    "        x_trn, x_vld = x.iloc[t_ind], x.iloc[v_ind]\n",
    "        y_trn, y_vld = y[t_ind], y[v_ind]\n",
    "\n",
    "        # fit model\n",
    "        model.fit(x_trn, y_trn)\n",
    "        \n",
    "        # eval _ trn        \n",
    "        preds = model.predict_proba(x_trn)\n",
    "\n",
    "        log_scores = trn_scores.get('log loss', [])\n",
    "        log_scores.append(log_loss(y_trn, preds))\n",
    "        trn_scores['log loss'] = log_scores\n",
    "\n",
    "        # eval _ vld\n",
    "        preds = model.predict_proba(x_vld)\n",
    "\n",
    "        log_scores = vld_scores.get('log loss', [])\n",
    "        log_scores.append(log_loss(y_vld, preds))\n",
    "        vld_scores['log loss'] = log_scores\n",
    "    return trn_scores, vld_scores\n",
    "\n",
    "def print_scores(trn_scores, vld_scores):\n",
    "    prefix = '        '\n",
    "    cols = ['log loss']\n",
    "    print('='*50)\n",
    "    print('TRAIN EVAL')\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(trn_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, trn_scores[col]))\n",
    "\n",
    "    print('='*50)\n",
    "    print('VALID EVAL')\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(vld_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, vld_scores[col]))\n",
    "\n",
    "def print_time(end, start):\n",
    "    print('='*50)\n",
    "    elapsed = end - start\n",
    "    print('{} secs'.format(round(elapsed)))\n",
    "    \n",
    "def fit_and_eval(trn, target, model):\n",
    "    trn_scores, vld_scores = evaluate(trn,target,model)\n",
    "    print_scores(trn_scores, vld_scores)\n",
    "    print_time(time.time(), st)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 및 평가\n",
    "    - 모델 종류\n",
    "        - Decision Tree : 트리 기반 모델\n",
    "        - Logistic Regression : 선형 모델\n",
    "        - RandomForest, ExtraTrees : 트리 기반 앙상블 모델\n",
    "        - BaggingClassifier : 앙상블 모델\n",
    "        - (XGBoost) : 트리 기반 앙상블 모델\n",
    "        \n",
    "    - 훈련/검증 데이터 기반 평가 척도\n",
    "        - Log Loss\n",
    "        \n",
    "    - 검증 데이터 Log Loss 목표 수치 = 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2회차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=5,random_state=777)\n",
    "fit_and_eval(trn.fillna(0), target, dt_model)\n",
    "# 9 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3회차 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(max_depth=10, n_jobs=-1, random_state=777)\n",
    "fit_and_eval(trn, target, rf_model)\n",
    "# 5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et_model = ExtraTreesClassifier(max_depth=10, n_jobs=-1, random_state=777)\n",
    "fit_and_eval(trn, target, et_model)\n",
    "# 6 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bg_model = BaggingClassifier(n_estimators=5, n_jobs=-1, random_state=777)\n",
    "fit_and_eval(trn, target, bg_model)\n",
    "# 75 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 매개변수 및 주요 변수 시각화 (1)\n",
    "    - Decision Tree, RandomForest, ExtraTrees 전용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility\n",
    "\n",
    "def observe_model_tree(trn, model):\n",
    "    print('='*50)\n",
    "    print(model)\n",
    "    \n",
    "    print('='*50)\n",
    "    print('# Feature Importance')\n",
    "    print(model.feature_importances_)\n",
    "    \n",
    "    print('-'*50)\n",
    "    print('# Mapped to Column Name')\n",
    "    prefix = '    '\n",
    "    feature_importance = dict()\n",
    "    for i, f_imp in enumerate(model.feature_importances_):\n",
    "        print('{} {} \\t {}'.format(prefix, round(f_imp,5), trn.columns[i]))\n",
    "        feature_importance[trn.columns[i]] = f_imp\n",
    "\n",
    "    print('-'*50)\n",
    "    print('# Sorted Feature Importance')\n",
    "    feature_importance_sorted = sorted(feature_importance.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for item in feature_importance_sorted:\n",
    "        print('{} {} \\t {}'.format(prefix, round(item[1],5), item[0]))\n",
    "    \n",
    "    return feature_importance_sorted\n",
    "\n",
    "def plot_fimp(fimp):\n",
    "    x = []; y = []\n",
    "    for item in fimp:\n",
    "        x.append(item[0])\n",
    "        y.append(item[1])\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(20, 15))\n",
    "    sns.barplot(x,y,alpha=0.5)\n",
    "    ax.set_title('Feature Importance for Model : Decision Tree')\n",
    "    ax.set(xlabel='Column Name', ylabel='Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 모델 상세 보기\n",
    "dt_fimp = observe_model_tree(trn, dt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 주요 변수 시각화\n",
    "plot_fimp(dt_fimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 모델 상세 보기\n",
    "rf_fimp = observe_model_tree(trn, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 주요 변수 시각화\n",
    "plot_fimp(rf_fimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 모델 상세 보기\n",
    "et_fimp = observe_model_tree(trn, et_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 주요 변수 시각화\n",
    "plot_fimp(et_fimp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피쳐 엔지니어링 (데이터 최적화) [+2]\n",
    "    - 직접 새로운 변수를 추가 혹은 기존 변수를 삭제하여서 최적의 변수세트 생성해보기\n",
    "    - 주의: 훈련 데이터에 수행한 변수 변환은 테스트 데이터에도 동일하게 수행해야함\n",
    "    - 힌트: 금융 상품에 대한 새로운 정보를 넣는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 입력 : trn, target, tst\n",
    "# 출력 : new trn, new tst, same target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 매개변수 최적화 (모델 최적화) [+1]\n",
    "    - 사용하는 모델의 매개변수를 직접 정의하여 최적의 매개변수 찾아내기\n",
    "    - 참고: scikit learn 홈페이지를 통해 모델별 매개변수 확인 가능\n",
    "    - 힌트: trn/vld logloss 를 비교하여, 모델의 복잡도를 조정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 입력 : none\n",
    "# 출력: model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐글에 직접 결과물 제출하기\n",
    "    - MAP@7 평가척도를 기반 (https://www.kaggle.com/c/santander-product-recommendation/details/evaluation)\n",
    "    - 유저당 상위 7개의 제품을 추천해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 최종 모델 정의하기\n",
    "model = RandomForestClassifier(max_depth=20, n_jobs=-1, random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print('='*50)\n",
    "print('# Test shape : {}'.format(tst.shape))\n",
    "\n",
    "model.fit(trn,target)\n",
    "\n",
    "preds = model.predict_proba(tst)\n",
    "preds = np.fliplr(np.argsort(preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "        'ind_cder_fin_ult1', 'ind_cno_fin_ult1',  'ind_ctju_fin_ult1',\n",
    "        'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "        'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "        'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "        'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "        'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "        'ind_nomina_ult1',   'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "target_cols = [cols[i] for i, col in enumerate(cols) if i in rem_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in preds:\n",
    "    top_products = []\n",
    "    for i, product in enumerate(pred):\n",
    "        top_products.append(target_cols[product])\n",
    "        if i == 6:\n",
    "            break\n",
    "    final_preds.append(' '.join(top_products))\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "file_name = datetime.now().strftime(\"result_%Y%m%d%H%M%S\") + '.csv'\n",
    "out_df.to_csv(os.path.join('../output',file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과물 출력은 https://www.kaggle.com/c/santander-product-recommendation/submissions/attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나만의 머신러닝 파이프라인 흐름도(Flow Chart) 기록하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원천 데이터\n",
    "    - .\n",
    "\n",
    "- 전처리\n",
    "    - .\n",
    "\n",
    "- 피쳐 엔지니어링 이전 데이터 dimension\n",
    "    - .\n",
    "\n",
    "- 피쳐 엔지니어링 \n",
    "    - .\n",
    "\n",
    "- 피쳐 엔지니어링 이후 데이터 dimension\n",
    "    - .\n",
    "\n",
    "- 모델 튜닝 \n",
    "    - .\n",
    "\n",
    "- 검증 결과 \n",
    "    - .\n",
    "\n",
    "- 실제 결과 \n",
    "    - ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시\n",
    "\n",
    "- 원천 데이터 \n",
    "    - Kaggle 경진대회 데이터 train_ver2.csv, test_ver2.csv (Link: https://www.kaggle.com/c/santander-product-recommendation/data)\n",
    "\n",
    "\n",
    "- 전처리 \n",
    "    - 결측값을 .fillna 함수를 통해 0으로 대체. (기존 데이터에 0이 존재할 경우 -1로 대체)\n",
    "\n",
    "\n",
    "- 피쳐 엔지니어링 이전 데이터 dimension:\n",
    "    - trn : (45619, 246)\n",
    "    - target : (45619, 1) [18 classes]\n",
    "    - tst : (929615, 246)\n",
    "\n",
    "\n",
    "- 피쳐 엔지니어링\n",
    "    - age_log : log(age + 1)\n",
    "    - ind..._lag_one : 5월 사용자별 금융상품 보유현황\n",
    "    - ind..._lag_two : 4월 사용자별 금융상품 보유현황\n",
    "    - ind..._lag_thr : 3월 사용자별 금융상품 보유현황\n",
    "\n",
    "\n",
    "- 피쳐 엔지니어링 이후 데이터 dimension:\n",
    "    - trn : (45619, 250)\n",
    "    - target : (45619, 1) [18 classes]\n",
    "    - tst : (929615, 250)\n",
    "\n",
    "\n",
    "- 모델 튜닝 \n",
    "    - RandomForest : max_depth = 20 로 복잡도 조정\n",
    "\n",
    "\n",
    "- 검증 결과 \n",
    "    - trn logloss : 1.18\n",
    "    - vld logloss : 1.28\n",
    "\n",
    "\n",
    "- 실제 결과 \n",
    "    - Public Leaderboard : 0.025984\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "    - RandomForest vs ExtraTrees 의 차이란?\n",
    "        - P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”, Machine Learning, 63(1), 3-42, 2006\n",
    "        - 1) ET의 경우, 변수 샘플링을 boostrap 샘플이 아닌 전체 데이터에서 취한다.\n",
    "        - 2) ET의 경우, 샘플내 분포에 상관없이 완전한 임의 샘플링으로 데이터 샘플을 취한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
