{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    this file trians (user, target) pair using neural net\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = '../Data/Raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  test_ver2.csv  train.csv  train_ver2.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls ../Data/Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('../Data/Raw/train_ver2.csv','r')\n",
    "first_line = f.readline().strip()\n",
    "first_line = first_line.replace('\"','')\n",
    "map_names = first_line.split(',')[24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "while 1:\n",
    "    line = f.readline()[:-1]\n",
    "    total += 1\n",
    "    \n",
    "    if line == '':\n",
    "        break\n",
    "        \n",
    "    tmp1 = line.split('\"')\n",
    "    arr = tmp1[0][:-1].split(',') + [tmp1[1]] + tmp1[2][1:].split(',')\n",
    "    arr = [a.strip() for a in arr]\n",
    "    if len(arr) != 48:\n",
    "        print 'Error: len(arr) = {} !!!! {}'.format(len(arr), line)\n",
    "        exit()\n",
    "\n",
    "    # Feature Engineer\n",
    "\n",
    "    if total % 1000000 == 0:\n",
    "        print('Process {} lines ...'.format(total))\n",
    "        LOG.info('Process {} lines ...'.format(total))\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = f.readline()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp1 = line.split('\"')\n",
    "arr = tmp1[0][:-1].split(',') + [tmp1[1]] + tmp1[2][1:].split(',')\n",
    "arr = [a.strip() for a in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature engineer\n",
    "\n",
    "(fecha_dato, ncodpers, ind_empleado, pais_residencia, \\\n",
    "sexo, age, fecha_alta, ind_nuevo, antiguedad, indrel, \\\n",
    "ult_fec_cli_1t, indrel_1mes, tiprel_1mes, indresi, \\\n",
    "indext, conyuemp, canal_entrada, indfall, tipodom, \\\n",
    "cod_prov, nomprov, ind_actividad_cliente, renta, segmento, \\\n",
    "ahor, aval, cco, cder, cno, tju, ctma, ctop, ctpp, deco, \\\n",
    "deme, dela, ecue, fond, hip, plan, pres, reca, tjcr, valo, \\\n",
    "viv, nomina, nom_pens, recibo) = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# prep\n",
    "# files\n",
    "ind_empleado_unq_vld = pickle.load(open('../Data/Clean/unq_ind_empleado_vld.pkl','rb'))\n",
    "#antiguedad_unq_vld_user = pickle.load(open('../Data/Clean/unq_antiguedad_vld_per_user.pkl','rb'))\n",
    "#indrel_unq_vld_user = pickle.load(open('../Data/Clean/unq_indrel_vld_per_user.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_target = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# row-wise computation\n",
    "\n",
    "## fecha_alto\n",
    "# extract year and month\n",
    "fecha_dato_y, fecha_dato_m, _ = fecha_dato.split('-')\n",
    "fecha_dato_y = int(fecha_dato_y)\n",
    "fecha_dato_m = int(fecha_dato_m)\n",
    "\n",
    "## ncodpers\n",
    "'''\n",
    "## ind_empleado\n",
    "# one hot encoding of ind_empleado\n",
    "ind_empleado_ohe = [0]*ind_empleado_unq_vld['len']\n",
    "ind_empleado_ohe[list(ind_empleado_unq_vld['elements']) \\\n",
    "                 .index(ind_empleado)] = 1\n",
    "\n",
    "## pais_residencia\n",
    "# one hot encoding of pais_residencia\n",
    "pais_residencia_ohe = [0]*pais_residencia_unq_vld['len']\n",
    "pais_residencia_ohe[list(pais_residencia_unq_vld['elements']) \\\n",
    "                 .index(pais_residencia)] = 1\n",
    "\n",
    "## sexo\n",
    "# one hot encoding of sexo\n",
    "sexo_ohe = [0]*sexo_unq_vld['len']\n",
    "sexo_ohe[list(sexo_unq_vld['elements']) \\\n",
    "                 .index(sexo)] = 1\n",
    "'''\n",
    "## age\n",
    "try:\n",
    "    age = int(np.clip(int(float(age)),0,80)/5.)\n",
    "except:\n",
    "    age = -1\n",
    "\n",
    "## fecha_alta\n",
    "# fecha_alta month\n",
    "_, fecha_alta_m, _ = fecha_alta.split('-')\n",
    "fecha_alta_m = int(fecha_alta_m)\n",
    "# fecha_dato - fecha_alta\n",
    "try:\n",
    "    fecha_alta_d = datetime.strptime(fecha_alta, '%Y-%m-%d')\n",
    "    fecha_dato = datetime.strptime(fecha_dato, '%Y-%m-%d')\n",
    "    fecha_alta_d = (fecha_dato - fecha_alta_d).days / 30\n",
    "except:\n",
    "    fecha_alta_d = -1\n",
    "\n",
    "## ind_nuevo\n",
    "# as-is\n",
    "if '1' in ind_nuevo:\n",
    "    ind_nuevo = 1\n",
    "else:\n",
    "    ind_nuevo = 0\n",
    "    \n",
    "## antiguedad\n",
    "# n_unq\n",
    "#n_antiguedad = len(antiguedad_unq_vld_user[ncodpers]['elements'])\n",
    "# as-is\n",
    "try:\n",
    "    antiguedad = int(antiguedad)\n",
    "except:\n",
    "    antiguedad = -1\n",
    "'''    \n",
    "## indrel\n",
    "# n_unq\n",
    "n_indrel = len(indrel_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of indrel\n",
    "indrel_ohe = [0]*indrel_unq_vld['len']\n",
    "indrel_ohe[list(indrel_unq_vld['elements']) \\\n",
    "                 .index(indrel)] = 1\n",
    "'''\n",
    "## ult_fec_cli_1t\n",
    "# fecha_dato - ult_fec_cli_1t\n",
    "try:\n",
    "    ult_fec_cli_1t = datetime.strptime(ult_fec_cli_1t, '%Y-%m-%d')\n",
    "    fecha_dato = datetime.strptime(fecha_dato, '%Y-%m-%d')\n",
    "    ult_fec = (fecha_dato - ult_fec_cli_1t).days / 30\n",
    "except:\n",
    "    ult_fec = 0\n",
    "'''\n",
    "## indrel_1mes\n",
    "# n_unq\n",
    "n_indrel_1mes = len(indrel_1mes_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of indrel_1mes\n",
    "indrel_1mes_ohe = [0]*indrel_1mes_unq_vld['len']\n",
    "indrel_1mes_ohe[list(indrel_1mes_unq_vld['elements']) \\\n",
    "                 .index(indrel_1mes)] = 1\n",
    "    \n",
    "## tiprel_1mes\n",
    "# n_unq\n",
    "n_tiprel_1mes = len(tiprel_1mes_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of tiprel_1mes\n",
    "tiprel_1mes_ohe = [0]*tiprel_1mes_unq_vld['len']\n",
    "tiprel_1mes_ohe[list(tiprel_1mes_unq_vld['elements']) \\\n",
    "                 .index(tiprel_1mes)] = 1\n",
    "    \n",
    "## indresi\n",
    "# n_indresi\n",
    "n_indresi = len(indresi_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of indresi\n",
    "indresi_ohe = [0]*indresi_unq_vld['len']\n",
    "indresi_ohe[list(indresi_unq_vld['elements']) \\\n",
    "                 .index(indresi)] = 1\n",
    "\n",
    "## indext\n",
    "# n_indext\n",
    "n_indext = len(indext_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of indext\n",
    "indext_ohe = [0]*indext_unq_vld['len']\n",
    "indext_ohe[list(indext_unq_vld['elements']) \\\n",
    "                 .index(indext)] = 1\n",
    "\n",
    "## conyuemp\n",
    "# one hot encoding of conyuemp\n",
    "conyuemp_ohe = [0]*conyuemp_unq_vld['len']\n",
    "conyuemp_ohe[list(conyuemp_unq_vld['elements']) \\\n",
    "                 .index(conyuemp)] = 1\n",
    "    \n",
    "## canal_entrada\n",
    "# n_canal_entrada\n",
    "n_canal_entrada = len(canal_entrada_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of canal_entrada\n",
    "canal_entrada_ohe = [0]*canal_entrada_unq_vld['len']\n",
    "canal_entrada_ohe[list(canal_entrada_unq_vld['elements']) \\\n",
    "                 .index(canal_entrada)] = 1\n",
    "    \n",
    "## indfall\n",
    "# n_indfall\n",
    "n_indfall = len(indfall_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of indfall\n",
    "indfall_ohe = [0]*indfall_unq_vld['len']\n",
    "indfall_ohe[list(indfall_unq_vld['elements']) \\\n",
    "                 .index(indfall)] = 1\n",
    "'''\n",
    "## tipodom\n",
    "try:\n",
    "    tipodom = int(tipodom)\n",
    "except:\n",
    "    tipodom = 0\n",
    "'''\n",
    "## cod_prov\n",
    "# n_cod_prov\n",
    "n_cod_prov = len(cod_prov_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of cod_prov\n",
    "cod_prov_ohe = [0]*cod_prov_unq_vld['len']\n",
    "cod_prov_ohe[list(cod_prov_unq_vld['elements']) \\\n",
    "                 .index(cod_prov)] = 1\n",
    "    \n",
    "## nomprov\n",
    "# n_nomprov\n",
    "n_nomprov = len(nomprov_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of nomprov\n",
    "nomprov_ohe = [0]*nomprov_unq_vld['len']\n",
    "nomprov_ohe[list(nomprov_unq_vld['elements']) \\\n",
    "                 .index(nomprov)] = 1\n",
    "\n",
    "## ind_actividad_cliente\n",
    "# n_ind_actividad_cliente\n",
    "n_ind_actividad_cliente = len(ind_actividad_cliente_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of ind_actividad_cliente\n",
    "ind_actividad_cliente_ohe = [0]*ind_actividad_cliente_unq_vld['len']\n",
    "ind_actividad_cliente_ohe[list(ind_actividad_cliente_unq_vld['elements']) \\\n",
    "                 .index(ind_actividad_cliente)] = 1\n",
    "'''\n",
    "## renta\n",
    "try:\n",
    "    renta = int(float(renta))\n",
    "    if renta < 4158:\n",
    "        renta = '25%'\n",
    "    elif renta < 8364:\n",
    "        renta = '50%'\n",
    "    elif renta < 13745:\n",
    "        renta = '75%'\n",
    "    else:\n",
    "        renta = '100%'\n",
    "except:\n",
    "    renta = '-1'\n",
    "renta_var = [0]*5\n",
    "renta_var[['25%','50%','75%','100%','-1'].index(renta)] = 1\n",
    "\n",
    "'''\n",
    "## segmento\n",
    "# n_segmento\n",
    "n_segmento = len(segmento_unq_vld_user[ncodpers]['elements'])\n",
    "# one hot encoding of ind_actividad_cliente\n",
    "segmento_ohe = [0]*segmento_unq_vld['len']\n",
    "segmento_ohe[list(segmento_unq_vld['elements']) \\\n",
    "                 .index(segmento)] = 1\n",
    "'''\n",
    "## count of na\n",
    "na_count = arr.count('') + arr.count('nan') + arr.count('NA')\n",
    "\n",
    "## count of products on previous timeframe\n",
    "if ncodpers in prev_target:\n",
    "    product_count = sum([int(i) for i in prev_target[ncodpers]])\n",
    "else:\n",
    "    product_count = 0\n",
    "\n",
    "target = [0]*24\n",
    "## target\n",
    "for i in range(24):\n",
    "    if ncodpers in prev_target:\n",
    "        if arr[24+i] == '1' and prev_target[ncodpers][i] == '0':\n",
    "            target[i] = 1\n",
    "    else:\n",
    "        if arr[24+i] == '1':\n",
    "            target[i] = 1\n",
    "prev_target[ncodpers] = arr[24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = (fecha_dato_m, age, fecha_alta_m, fecha_alta_d, ind_nuevo, antiguedad, ult_fec, tipodom, renta_var, na_count, product_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 8, -1, 0, 35, 0, 1, [0, 0, 0, 0, 1], 3, 0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make feature with unq counts\n",
    "# make (feature, label) dataset to feed into keras\n",
    "# feed into keras and train\n",
    "# predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
